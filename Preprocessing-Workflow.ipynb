{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "ruta_del_archivo = 'Dataset.csv'\n",
    "data = pd.read_csv(ruta_del_archivo, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas: 1054\n",
      "Número de columnas: 18\n"
     ]
    }
   ],
   "source": [
    "num_filas, num_columnas = data.shape\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Número de filas:\", num_filas)\n",
    "print(\"Número de columnas:\", num_columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case_No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
       "Case_No                                                                      \n",
       "1         0   0   0   0   0   0   1   1   0    1        28               3   \n",
       "2         1   1   0   0   0   1   1   0   0    0        36               4   \n",
       "3         1   0   0   0   0   0   1   1   0    1        36               4   \n",
       "4         1   1   1   1   1   1   1   1   1    1        24              10   \n",
       "5         1   1   0   1   1   1   1   1   1    1        20               9   \n",
       "\n",
       "        Sex       Ethnicity Jaundice Family_mem_with_ASD  \\\n",
       "Case_No                                                    \n",
       "1         f  middle eastern      yes                  no   \n",
       "2         m  White European      yes                  no   \n",
       "3         m  middle eastern      yes                  no   \n",
       "4         m        Hispanic       no                  no   \n",
       "5         f  White European       no                 yes   \n",
       "\n",
       "        Who completed the test Class/ASD Traits   \n",
       "Case_No                                           \n",
       "1                family member                No  \n",
       "2                family member               Yes  \n",
       "3                family member               Yes  \n",
       "4                family member               Yes  \n",
       "5                family member               Yes  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#duplicados\n",
    "duplicate_count = len(data) - len(data.drop_duplicates()) # Original data length minus data length without duplicates\n",
    "duplicate_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case_No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>m</td>\n",
       "      <td>black</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>m</td>\n",
       "      <td>asian</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>975 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
       "Case_No                                                                      \n",
       "1         0   0   0   0   0   0   1   1   0    1        28               3   \n",
       "2         1   1   0   0   0   1   1   0   0    0        36               4   \n",
       "3         1   0   0   0   0   0   1   1   0    1        36               4   \n",
       "4         1   1   1   1   1   1   1   1   1    1        24              10   \n",
       "5         1   1   0   1   1   1   1   1   1    1        20               9   \n",
       "...      ..  ..  ..  ..  ..  ..  ..  ..  ..  ...       ...             ...   \n",
       "1050      0   0   0   0   0   0   0   0   0    1        24               1   \n",
       "1051      0   0   1   1   1   0   1   0   1    0        12               5   \n",
       "1052      1   0   1   1   1   1   1   1   1    1        18               9   \n",
       "1053      1   0   0   0   0   0   0   1   0    1        19               3   \n",
       "1054      1   1   0   0   1   1   0   1   1    0        24               6   \n",
       "\n",
       "        Sex       Ethnicity Jaundice Family_mem_with_ASD  \\\n",
       "Case_No                                                    \n",
       "1         f  middle eastern      yes                  no   \n",
       "2         m  White European      yes                  no   \n",
       "3         m  middle eastern      yes                  no   \n",
       "4         m        Hispanic       no                  no   \n",
       "5         f  White European       no                 yes   \n",
       "...      ..             ...      ...                 ...   \n",
       "1050      f  White European       no                 yes   \n",
       "1051      m           black      yes                  no   \n",
       "1052      m  middle eastern      yes                  no   \n",
       "1053      m  White European       no                 yes   \n",
       "1054      m           asian      yes                 yes   \n",
       "\n",
       "        Who completed the test Class/ASD Traits   \n",
       "Case_No                                           \n",
       "1                family member                No  \n",
       "2                family member               Yes  \n",
       "3                family member               Yes  \n",
       "4                family member               Yes  \n",
       "5                family member               Yes  \n",
       "...                        ...               ...  \n",
       "1050             family member                No  \n",
       "1051             family member               Yes  \n",
       "1052             family member               Yes  \n",
       "1053             family member                No  \n",
       "1054             family member               Yes  \n",
       "\n",
       "[975 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(inplace=True) # Drop duplicates in place\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar las columnas de:\n",
    "#Age_mons\n",
    "#Qchat-10-Score\n",
    "#Ethnicity\n",
    "#Jaundice\n",
    "#Who completed the text\n",
    "#y convertir el resto en binario para revisar al final la colinealidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos en el DataFrame:\n",
      "A1                         int64\n",
      "A2                         int64\n",
      "A3                         int64\n",
      "A4                         int64\n",
      "A5                         int64\n",
      "A6                         int64\n",
      "A7                         int64\n",
      "A8                         int64\n",
      "A9                         int64\n",
      "A10                        int64\n",
      "Age_Mons                   int64\n",
      "Qchat-10-Score             int64\n",
      "Sex                       object\n",
      "Ethnicity                 object\n",
      "Jaundice                  object\n",
      "Family_mem_with_ASD       object\n",
      "Who completed the test    object\n",
      "Class/ASD Traits          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "tipos_de_datos = data.dtypes\n",
    "\n",
    "# Imprime los tipos de datos para cada columna\n",
    "print(\"Tipos de datos en el DataFrame:\")\n",
    "print(tipos_de_datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons',\n",
      "       'Qchat-10-Score', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD',\n",
      "       'Who completed the test', 'Class/ASD Traits '],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_elim=['Age_Mons', 'Qchat-10-Score', 'Ethnicity', 'Jaundice', 'Who completed the test']\n",
    "data= data.drop(columnas_elim, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame después de eliminar columnas:\n",
      "         A1  A2  A3  A4  A5  A6  A7  A8  A9  A10 Sex Family_mem_with_ASD  \\\n",
      "Case_No                                                                    \n",
      "1         0   0   0   0   0   0   1   1   0    1   f                  no   \n",
      "2         1   1   0   0   0   1   1   0   0    0   m                  no   \n",
      "3         1   0   0   0   0   0   1   1   0    1   m                  no   \n",
      "4         1   1   1   1   1   1   1   1   1    1   m                  no   \n",
      "5         1   1   0   1   1   1   1   1   1    1   f                 yes   \n",
      "...      ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..                 ...   \n",
      "1050      0   0   0   0   0   0   0   0   0    1   f                 yes   \n",
      "1051      0   0   1   1   1   0   1   0   1    0   m                  no   \n",
      "1052      1   0   1   1   1   1   1   1   1    1   m                  no   \n",
      "1053      1   0   0   0   0   0   0   1   0    1   m                 yes   \n",
      "1054      1   1   0   0   1   1   0   1   1    0   m                 yes   \n",
      "\n",
      "        Class/ASD Traits   \n",
      "Case_No                    \n",
      "1                      No  \n",
      "2                     Yes  \n",
      "3                     Yes  \n",
      "4                     Yes  \n",
      "5                     Yes  \n",
      "...                   ...  \n",
      "1050                   No  \n",
      "1051                  Yes  \n",
      "1052                  Yes  \n",
      "1053                   No  \n",
      "1054                  Yes  \n",
      "\n",
      "[975 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame después de eliminar columnas:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertir en 0 y 1 las siguientes features\n",
    "#Sex   \n",
    "#Family_mem_with_ASD      \n",
    "#Class/ASD Traits          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame después de la conversión:\n",
      "         A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Sex Family_mem_with_ASD  \\\n",
      "Case_No                                                                     \n",
      "1         0   0   0   0   0   0   1   1   0    1    0                  no   \n",
      "2         1   1   0   0   0   1   1   0   0    0    1                  no   \n",
      "3         1   0   0   0   0   0   1   1   0    1    1                  no   \n",
      "4         1   1   1   1   1   1   1   1   1    1    1                  no   \n",
      "5         1   1   0   1   1   1   1   1   1    1    0                 yes   \n",
      "...      ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...                 ...   \n",
      "1050      0   0   0   0   0   0   0   0   0    1    0                 yes   \n",
      "1051      0   0   1   1   1   0   1   0   1    0    1                  no   \n",
      "1052      1   0   1   1   1   1   1   1   1    1    1                  no   \n",
      "1053      1   0   0   0   0   0   0   1   0    1    1                 yes   \n",
      "1054      1   1   0   0   1   1   0   1   1    0    1                 yes   \n",
      "\n",
      "        Class/ASD Traits   sex  \n",
      "Case_No                         \n",
      "1                      No    0  \n",
      "2                     Yes    1  \n",
      "3                     Yes    1  \n",
      "4                     Yes    1  \n",
      "5                     Yes    0  \n",
      "...                   ...  ...  \n",
      "1050                   No    0  \n",
      "1051                  Yes    1  \n",
      "1052                  Yes    1  \n",
      "1053                   No    1  \n",
      "1054                  Yes    1  \n",
      "\n",
      "[975 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "data['Sex'] = data['Sex'].map({'f': 0, 'm': 1})\n",
    "data['Family_mem_with_ASD'] = data['Family_mem_with_ASD'].map({'f': 0, 'm': 1})\n",
    "\n",
    "# Muestra el DataFrame después de la conversión\n",
    "print(\"\\nDataFrame después de la conversión:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Print the percentage of missing values for every column of the dataframe. ❓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "round(data.isnull().sum().sort_values(ascending=False)/len(data),2) #NaN percentage for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GarageFinish`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Questions** about `GarageFinish` ❓\n",
    "\n",
    "Investigate the missing values in `GarageFinish`. Then, choose one of the following solutions:\n",
    "\n",
    "1. Drop the column entirely\n",
    "2. Impute the column median using `SimpleImputer` from Scikit-Learn\n",
    "3. Preserve the NaNs and replace them with meaningful values\n",
    "\n",
    "Make changes effective in the dataframe `data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>💡 <i>Hint</i></summary>\n",
    "    \n",
    "ℹ️ According to the dataset description, the missing values in `GarageFinish` represent a house having no garage. They need to be encoded as such.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data.GarageFinish.replace(np.nan, \"NoGarage\", inplace=True) #Replace NaN by \"NoGarage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RoofSurface`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Questions** about `RoofSurface` ❓\n",
    "\n",
    "Investigate the missing values in `RoofSurface`. Then, choose one of the following solutions:\n",
    "\n",
    "1. Drop the column entirely\n",
    "2. Impute the column median using sklearn's `SimpleImputer`\n",
    "3. Preserve the NaNs and replace them with meaningful values\n",
    "\n",
    "Make changes effective in the dataframe `data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>💡 <i>Hint</i></summary>\n",
    "    \n",
    "ℹ️ `RoofSurface` has a few missing values that can be imputed by the median value.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") # Instanciate a SimpleImputer object with strategy of choice\n",
    "\n",
    "imputer.fit(data[['RoofSurface']]) # Call the \"fit\" method on the object\n",
    "\n",
    "data['RoofSurface'] = imputer.transform(data[['RoofSurface']]) # Call the \"transform\" method on the object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ChimneyStyle`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Questions** about `ChimneyStyle` ❓\n",
    "\n",
    "Investigate the missing values in `ChimneyStyle`. Then, choose one of the following solutions:\n",
    "\n",
    "1. Drop the column entirely\n",
    "2. Impute the column median\n",
    "3. Preserve the NaNs and replace them with meaningful values\n",
    "\n",
    "Make changes effective in the dataframe `data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>💡 <i>Hint</i></summary>\n",
    "    \n",
    "* ⚠️ Be careful: not all missing values are represented as `np.nans`, and Python's `isnull()` only detects `np.nans`...\n",
    "    \n",
    "* ℹ️ `ChimneyStyle` has a lot of missing values. The description does not touch on what they represent. As such, it is better not to make any assumptions and to drop the column entirely.\n",
    "    \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "data.ChimneyStyle.value_counts(dropna=False) # Get unique values and their count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "data.ChimneyStyle.replace(\"?\",np.nan, inplace=True) # Replace \"?\" by np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "data.ChimneyStyle.isnull().sum()/len(data) # NaN percentage for Chimney Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "data.drop(columns='ChimneyStyle', inplace=True) # Drop ChimneyStyle column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧪 **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('missing_values',\n",
    "                         dataset = data\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ When you are done with handling missing value, print out the percentage of missing values for the entire dataframe ❓\n",
    "\n",
    "You should no longer have missing values !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "round(data.isnull().sum().sort_values(ascending=False)/len(data),2) #NaN percentage for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First of all, before scaling...**\n",
    "\n",
    "To understand the effects of scaling and encoding on model performance, let's get a **base score without any data transformation**.\n",
    "\n",
    "❓ Cross-validate a linear regression model that predicts `SalePrice` using the other features ❓\n",
    "\n",
    "⚠️ Note that a linear regression model can only handle numeric features. [DataFrame.select_dtypes](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html) can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# excluding all non-numeric columns and the target\n",
    "X = data.select_dtypes(exclude='object').drop('SalePrice', axis=1)\n",
    "\n",
    "y = data.SalePrice\n",
    "\n",
    "cross_val_score(LinearRegression(), X, y, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep this score in mind! You will train a new model after data preprocessing in Challenge #2 - see if it improves your average score 😉\n",
    "\n",
    "🚀 Now, back to **feature scaling**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `RoofSurface` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** about `RoofSurface` ❓\n",
    "\n",
    "👇 Investigate `RoofSurface` for distribution and outliers. Then, choose the most appropriate scaling technique. Either:\n",
    "\n",
    "1. Standard Scaler\n",
    "2. Robust Scaler\n",
    "3. MinMax Scaler\n",
    "\n",
    "Replace the original columns with the transformed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "data[['RoofSurface']].boxplot()\n",
    "data[['RoofSurface']].plot.hist(bins=20)\n",
    "\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "qqplot(data[['RoofSurface']],line='s');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>💡 <i>Hint</i></summary>\n",
    "    \n",
    "ℹ️ Since `RoofSurface` has neither a Gaussian distribution, nor outliers $\\rightarrow$ MinMaxScaler.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmaxscaler = MinMaxScaler()\n",
    "data['RoofSurface']= minmaxscaler.fit_transform(data[['RoofSurface']])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GrLivArea`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** about `GrLivArea` ❓\n",
    "\n",
    "👇 Investigate `GrLivArea` for distribution and outliers. Then, choose the most appropriate scaling technique. Either:\n",
    "\n",
    "1. Standard Scaler\n",
    "2. Robust Scaler\n",
    "3. MinMax Scaler\n",
    "\n",
    "Replace the original columns with the transformed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "data[['GrLivArea']].boxplot()\n",
    "data[['GrLivArea']].plot.hist(bins=20)\n",
    "qqplot(data[['GrLivArea']],line='s');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>💡 <i>Hint</i></summary>\n",
    "    \n",
    "ℹ️ `GrLivArea` has many outliers $\\rightarrow$ RobustScaler()\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "rb_scaler = RobustScaler()\n",
    "data['GrLivArea'] = rb_scaler.fit_transform(data[['GrLivArea']])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BedroomAbvGr` ,  `OverallCond` & `KitchenAbvGr`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Questions** about `BedroomAbvGr`, `OverallCond` & `KitchenAbvGr` ❓\n",
    "\n",
    "👇 Investigate `BedroomAbvGr`, `OverallCond` & `KitchenAbvGr`. Then, chose one of the following scaling techniques:\n",
    "\n",
    "1. MinMax Scaler\n",
    "2. Standard Scaler\n",
    "3. Robust Scaler\n",
    "\n",
    "Replace the original columns with the transformed values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>💡 <i>Hint</i></summary>\n",
    "    \n",
    "ℹ️ `BedroomAbvGr` ,  `OverallCond` & `KitchenAbvGr` are ordinal features. There are less than 0.1% of outliers so no need to use _RobustScaler()_. The distribution is not Gaussian, hence no _StandardScaler()_. By elimination, you can confidently choose _MinMaxScaler()_.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmaxscaler_2 = MinMaxScaler()\n",
    "\n",
    "data['BedroomAbvGr'], data['OverallCond'], data['KitchenAbvGr'] =  minmaxscaler_2.fit_transform(data[['BedroomAbvGr','OverallCond','KitchenAbvGr']]).T\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧪 **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('scaling',\n",
    "                         dataset = data\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GarageFinish`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** about `GarageFinish`❓\n",
    "\n",
    "👇 Investigate `GarageFinish` and choose one of the following encoding techniques accordingly:\n",
    "- Ordinal encoding\n",
    "- One-Hot encoding\n",
    "\n",
    "Add the encoding to the dataframe as new colum(s), and remove the original column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>💡 <i>Hint</i></summary>\n",
    "        \n",
    "ℹ️ `GarageFinish` is a multicategorical feature that should be One-hot-encoded. You could also consider an Ordinal Encoding but we would have to know for sure that Unfinished or no garage are definitely worse that rough finished!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "data.GarageFinish.unique() # Check unique categories in GarageFinish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "GarageFinish_ohe = OneHotEncoder(sparse_output = True) # Instanciate One hot encoder\n",
    "\n",
    "GarageFinish_ohe.fit(data[['GarageFinish']]) # Fit one hot encoder\n",
    "\n",
    "GarageFinish_ohe.categories_ # View categories of GarageFinish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GarageFinish_ohe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "data[GarageFinish_ohe.get_feature_names_out()] = GarageFinish_ohe.fit_transform(data[['GarageFinish']])\n",
    "\n",
    "data.drop(columns=['GarageFinish'], inplace = True) # Drop original column\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding  `CentralAir`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** about `CentralAir`❓\n",
    "\n",
    "Investigate `CentralAir` and choose one of the following encoding techniques accordingly:\n",
    "- Ordinal encoding\n",
    "- One-Hot encoding\n",
    "\n",
    "Replace the original column with the newly generated encoded columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>💡 <i>Hint</i></summary>\n",
    "    \n",
    "ℹ️ `CentralAir` is a binary categorical feature.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "data.CentralAir.unique() # Check unique values of CentralAir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "CentralAir_encoder = OneHotEncoder(sparse=False, drop='if_binary', categories=[['N', 'Y']]) # Instanciate encoder\n",
    "\n",
    "data['CentralAir'] = CentralAir_encoder.fit_transform(data[['CentralAir']]) # Fit encoder and tranform\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MoSold` - Cyclical engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👨🏻‍🏫 A feature can be numerical (continuous or discrete), categorical or ordinal. But a feature can also be temporal (e.g. quarters, months, days, minutes, ...). \n",
    "\n",
    "Cyclical features like time need some specific preprocessing. Indeed, if you want any Machine Learning algorithm to capture this cyclicity, your cyclical features must be preprocessed in a certain way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 Consider the feature `MoSold`, the month on which the house was sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MoSold\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Many houses were sold in June (6), July (7) and May (5) (Spring/Summer)\n",
    "* Only a few houses were sold in December (12), January (1) and February (2) (~ Fall/Winter)\n",
    "    * But for any Machine Learning model, there is no reason why December (12) and January (1) would be \"close\"..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👩🏻‍🏫 ***How to deal with cyclical features?***\n",
    "\n",
    "1.  Look at the following illustration and read the explanations to distinguish two different months.\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/02-Prepare-the-dataset/cyclical_feature_engineering.png\" alt=\"Cyclical features\" width=\"1000\">\n",
    "\n",
    "\n",
    "2. Read this [article](https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/) for more details.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** about `MoSold` ❓ \n",
    "- Create two new features `sin_MoSold` and `cos_MoSold` which correspond respectively to the sine and cosine of MoSold.\n",
    "- Drop the original column `MoSold`\n",
    "\n",
    "<details>\n",
    "    <summary>💡 <i>Hint</i></summary>\n",
    "    \n",
    "To create a time engineered feature based on a column which gives the second in the day!\n",
    "```python\n",
    "seconds_in_day = 24*60*60\n",
    "\n",
    "df['sin_time'] = np.sin(2*np.pi*df.seconds/seconds_in_day)\n",
    "df['cos_time'] = np.cos(2*np.pi*df.seconds/seconds_in_day)\n",
    "df.drop(columns=['seconds'], inplace=True)\n",
    "\n",
    "df.head()\n",
    "```\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "months_in_a_year = 12\n",
    "\n",
    "data['sin_MoSold'] = np.sin(2*np.pi*(data.MoSold)/months_in_a_year)\n",
    "data['cos_MoSold'] = np.cos(2*np.pi*(data.MoSold)/months_in_a_year)\n",
    "data.drop(columns=['MoSold'], inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "source": [
    "<u>Remarks</u>:\n",
    "- The -1 is not mandatory because sine and cosine functions have a $ 2 \\pi$ periodicity\n",
    "- However, it is more correct  speaking in terms of trigonometry properties to include it because $cos(0) = 1$ and $sin(0) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧪 **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('encoding', dataset = data, new_features = ['sin_MoSold', 'cos_MoSold'])\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Export the preprocessed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Now that the dataset has been preprocessed, execute the code below to export it. You will keep working on it in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/clean_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏁 Congratulations! Now, you know how to ***preprocess a dataset*** !\n",
    "\n",
    "💾 Don't forget to git add/commit/push your notebook...\n",
    "\n",
    "🚀 ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
